{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dcb9652-a204-4f48-9f6c-6537eb6ac561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624b8d7-61b3-4788-badc-6795b1d2e36f",
   "metadata": {},
   "source": [
    "# Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13d73479-7b7b-4e93-a847-9f80383a1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(units_each_layer: list[int]):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    params = {}\n",
    "    L = len(units_each_layer)  # number of layers\n",
    "    for i in range(1, L):\n",
    "        params[f'W{i}'] = np.random.randn(units_each_layer[i], units_each_layer[i-1]) * 0.01  # mean=0, std=0.01\n",
    "        params[f'b{i}'] = np.zeros(shape=(units_each_layer[i], 1))\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdd15047-cb89-4ab5-8e90-c0b46620c9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.00496714, -0.00138264],\n",
       "        [ 0.00647689,  0.0152303 ],\n",
       "        [-0.00234153, -0.00234137]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[ 0.01579213,  0.00767435, -0.00469474]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_params([2,3,1])  # 3 layers, layer 1 contains 2 units, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5803bf-428c-4863-ac84-5ecb57dc501c",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "379878b6-e809-4f0f-b657-c556cb61fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87430ef1-cb6d-4350-b450-fa01b670bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    A = np.maximum(0, Z)\n",
    "    cache = Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02478a5-feef-4294-95fe-28e8ff187944",
   "metadata": {},
   "source": [
    "# Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e058ab4-4f3a-4bdf-8709-a07c8066d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_linearly(A_prev, W, B):\n",
    "    Z = W @ A_prev + B\n",
    "    cache = (A_prev, W, B)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfbf82b9-c08a-4804-a879-846ba510f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_through_activation(A_prev, W, B, activation):\n",
    "    if activation == 'sigmoid':\n",
    "        Z, linear_cache = forward_linearly(A_prev, W, B)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        \n",
    "    elif activation == 'relu':\n",
    "        Z, linear_cache = forward_linearly(A_prev, W, B)\n",
    "        A, activation_cache = relu(Z)\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "217b9f54-9f07-4377-bd81-bd5fb37206c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, params):\n",
    "    A = X  # X is the initial A\n",
    "    L = len(params) // 2  # each layer linked with 2 params W, B\n",
    "    \n",
    "    caches = []\n",
    "    \n",
    "    # Forward Pass in Hidden Layers\n",
    "    for i in range(1, L):\n",
    "        A_prev = A\n",
    "        W, B = params[f'W{i}'], params[f'B{i}']\n",
    "        \n",
    "        A, cache = forward_through_activation(A_prev, W, B, activation='relu')\n",
    "        caches.append(cache)\n",
    "\n",
    "    # Forward Pass in Output Layer\n",
    "    W, B = params[f'W{L}'], params[f'B{L}']\n",
    "    Y_pred, cache = forward_through_activation(A_prev, W, B, activation='sigmoid')\n",
    "    caches.append(cache)\n",
    "\n",
    "    return Y_pred, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3660692e-c170-422b-a2b0-139018f2b9dd",
   "metadata": {},
   "source": [
    "# Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83705d18-9d38-4793-a401-3354f0630661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y_pred, Y):  # Binary Cross-Entropy\n",
    "    n_samples = Y.shape[1]\n",
    "    cost = -(1/n_samples) * np.sum(Y * np.log(Y_pred) + (1-Y) * np.log(1-Y_pred))\n",
    "    cost = np.squeeze(cost)  # turns [[cost]] into cost\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da763f-c59e-49d5-8ed3-36a5491181ce",
   "metadata": {},
   "source": [
    "# Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77a0974-dc99-4424-a377-77dd1e66f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_through_costFunc(Y, Y_pred, cost_func):\n",
    "    \"\"\"\n",
    "    Y: (1, n_samples)\n",
    "    Y_pred: (1, n_samples)\n",
    "    \"\"\"\n",
    "    if cost_func == 'binary_cross_entropy':\n",
    "        dY_pred = - (np.divide(Y, Y_pred) - np.divide(1-Y, 1-Y_pred))\n",
    "    return dY_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc6ddb5a-f775-4cd0-999f-836a16c5c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_through_activation(dA, activation_cache, activation):\n",
    "    \"\"\"\n",
    "    dA: (n_features_out, n_samples)\n",
    "    Z: (n_features_out, n_samples)\n",
    "    \"\"\"\n",
    "    Z = activation_cache\n",
    "    \n",
    "    if activation == 'sigmoid':\n",
    "        p = 1 / (1 + np.exp(-Z))\n",
    "        dA_dZ = p * (1 - p)\n",
    "        dZ = dA * dA_dZ\n",
    "\n",
    "    elif activation == 'relu':\n",
    "        dA_dZ = np.array(Z, copy=True)  \n",
    "        dA_dZ[Z <= 0] = 0  # when Z <= 0, set dZ to 0\n",
    "        dA_dZ[Z > 0] = 1  # when Z > 0, set dZ to 1\n",
    "        dZ = dA * dA_dZ\n",
    "\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce6c23cd-fa2a-4647-bf96-0cbfcc351368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_linearly(dZ, linear_cache):\n",
    "    \"\"\"\n",
    "    dZ: (n_features_out, n_samples)\n",
    "    A_prev: (n_features_in, n_samples)\n",
    "    W: (n_features_out, n_features_in)\n",
    "    B: (n_features_out, 1)\n",
    "    \"\"\"\n",
    "    A_prev, W, B = linear_cache\n",
    "    \n",
    "    n_samples = A_prev.shape[1]\n",
    "    \n",
    "    dW = (1/m) * (dZ @ A_prev.T)  # (n_features_out, n_samples) @ (n_samples, n_features_in)\n",
    "    dB = (1/m) * np.sum(dZ, axis=1, keepdims=True)  # sum all samples each row of (n_features_out, n_samples)\n",
    "    dA_prev = W.T @ dZ  # (n_features_in, n_features_out) @ (n_features_out, n_samples)\n",
    "\n",
    "    return dA_prev, dW, dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dce124a-89e9-4900-a1b4-30e2ddabe69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_each_layer(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        dZ = backward_through_activation(dA, activation_cache, activation='relu')\n",
    "    elif activation == 'sigmoid':\n",
    "        dZ = backward_through_activation(dA, activation_cache, activation='sigmoid')\n",
    "\n",
    "    dA_prev, dW, dB = backward_linearly(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecd3fbf4-6704-4e0f-bd09-f76f96e4f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(Y, Y_pred, caches):  # Y shape (n_samples, )\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    \n",
    "    Y = Y.reshape(Y_pred.shape)  # Y and Y_pred must have the same shape (1, n_samples)\n",
    "    dY_pred = backward_through_costFunc(Y, Y_pred, cost_func='binary_cross_entropy')\n",
    "    \n",
    "    last_cache = caches[-1]  # cache[L-1]\n",
    "    dA_prev, dW, dB = backward_each_layer(dY_pred, last_cache, activation='sigmoid')\n",
    "    grads[f'dA{L-1}'] = dA_prev\n",
    "    grads[f'dW{L}'] = dW\n",
    "    grads[f'dB{L}'] = dB\n",
    "\n",
    "    for i in range(L-1, 0, -1):  # from L-1 to 1\n",
    "        dA = dA_prev\n",
    "        current_cache = caches[i-1]  # from cache[L-2] to cache[0]\n",
    "        dA_prev, dW, dB = backward_each_layer(dA, current_cache, activation='sigmoid')\n",
    "        grads[f'dA{i-1}'] = dA_prev  # to dA0\n",
    "        grads[f'dW{i}'] = dW\n",
    "        grads[f'dB{i}'] = dB\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc047da-9b47-449b-b7a2-c9edfd03484b",
   "metadata": {},
   "source": [
    "# Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371f7bda-e4ef-495a-9370-3c86cf3cf7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(params, grads, learning_rate=0.01):\n",
    "    L = len(params) // 2\n",
    "    for i in range(1, L+1):\n",
    "        params[f'W{i}'] = params[f'W{i}'] - learning_rate * grads[f'dW{i}']\n",
    "        params[f'B{i}'] = params[f'B{i}'] - learning_rate * grads[f'dB{i}']\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb741c13-a41c-4335-a564-4aae895a8930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
